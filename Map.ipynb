{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1960b490",
   "metadata": {},
   "source": [
    "# Stage 1: Map Matching\n",
    "\n",
    "## **Input**: trajectories, \n",
    "\n",
    "## **Output**: each GPS point should have one corresponding matched road segment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16045bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "import os, sys\n",
    "import math\n",
    "from shapely.geometry import shape, Point, LineString, MultiLineString\n",
    "from sklearn.metrics.pairwise import haversine_distances \n",
    "\n",
    "\n",
    "RADIUS_OF_EARTH_M = 6371000\n",
    "MILES_PER_METER = 0.000621371\n",
    "HOURS_PER_SECOND = 3600.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af455a96",
   "metadata": {},
   "source": [
    "# Basic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6127239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# great circle distance \n",
    "def great_circle_dist_x_to_z(x, z):\n",
    "    # convert decimal degrees to radians \n",
    "    x = np.deg2rad(x)\n",
    "    z = np.deg2rad(z)\n",
    "    \n",
    "    longitude = z[1]\n",
    "    latitude = z[0]\n",
    "    prev_longitude = x[1]\n",
    "    prev_latitude = x[0]\n",
    "    \n",
    "    # haversine formula \n",
    "    dlon = longitude - prev_longitude # lon2 - lon1 \n",
    "    dlat = latitude - prev_latitude # lat2 - lat1 \n",
    "    \n",
    "    # a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    a = np.add(np.square(np.sin(dlat / 2)),\n",
    "               np.multiply(np.cos(prev_latitude), \n",
    "                           np.multiply(np.cos(latitude), np.square(np.sin(dlon / 2)))\n",
    "                          )\n",
    "              )\n",
    "    \n",
    "    # c = 2 * asin(sqrt(a)) \n",
    "    c = np.arcsin(np.sqrt(a)) * 2\n",
    "    \n",
    "    return RADIUS_OF_EARTH_M * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570315fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# great circle distance \n",
    "def great_circle_dist_z_to_z(df):\n",
    "    # convert decimal degrees to radians \n",
    "    df = df.copy()\n",
    "    df = np.deg2rad(df)\n",
    "    \n",
    "    longitude = df[:, 3]\n",
    "    latitude = df[:, 2]\n",
    "    prev_longitude = df[:, 1]\n",
    "    prev_latitude = df[:, 0]\n",
    "    \n",
    "    # haversine formula \n",
    "    dlon = longitude - prev_longitude # lon2 - lon1 \n",
    "    dlat = latitude - prev_latitude # lat2 - lat1 \n",
    "    \n",
    "    # a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    a = np.add(np.square(np.sin(dlat / 2)),\n",
    "               np.multiply(np.cos(prev_latitude), \n",
    "                           np.multiply(np.cos(latitude), np.square(np.sin(dlon / 2)))\n",
    "                          )\n",
    "              )\n",
    "    \n",
    "    # c = 2 * asin(sqrt(a)) \n",
    "    c = np.arcsin(np.sqrt(a)) * 2\n",
    "    \n",
    "    return RADIUS_OF_EARTH_M * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f516bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the x_t_i\n",
    "def get_perpendicular_point(point, line):\n",
    "    # point: (x, y)\n",
    "    # line: ((x1, y1), (x2, y2))\n",
    "    \n",
    "    x, y = point\n",
    "    x1, y1 = line[0]\n",
    "    x2, y2 = line[1]\n",
    "    \n",
    "    # calculate the slope of the line\n",
    "    if x2 - x1 == 0:\n",
    "        # vertical line\n",
    "        x_intersect = x1\n",
    "        y_intersect = y\n",
    "    else:\n",
    "        slope = (y2 - y1) / (x2 - x1)\n",
    "        intercept = y1 - slope * x1\n",
    "    \n",
    "        # calculate the intersection point of the line and the perpendicular line\n",
    "        x_intersect = (slope*y + x - slope*intercept) / (slope**2 + 1)\n",
    "        y_intersect = (slope*x_intersect) + intercept\n",
    "        \n",
    "    return [x_intersect, y_intersect]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bf726",
   "metadata": {},
   "source": [
    "# HMM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ce707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HMM model\n",
    "class HMMModel(nn.Module):\n",
    "    def __init__(self, sigma = 4.07, beta = 3.0, normalize=True, \n",
    "                 prob_floor=0.0, n = 50, viterbi_trellis=[], \n",
    "                 prev_candidate_roads = [], viterbi_list =[]):\n",
    "        self.normalize = normalize\n",
    "        self.prob_floor = min(max(prob_floor, 0), 1)\n",
    "        self.n = n\n",
    "        self.sigma = sigma\n",
    "        self.beta = beta\n",
    "        self.weights = np.zeros((1, self.n))\n",
    "        self.viterbi_trellis = viterbi_trellis  # list of particle np arrays\n",
    "        self.prev_candidate_roads = prev_candidate_roads\n",
    "        self.viterbi_list = viterbi_list\n",
    "      \n",
    "    def apply_emission_model(self, sampled_states, obs_coords):\n",
    "        # TODO: simplify the code below\n",
    "        # get the sigma \n",
    "        # 1.4826 medianð‘¡(â€–ð‘§ð‘¡ âˆ’ ð‘¥ð‘¡,ð‘–âˆ—â€–ð‘”ð‘Ÿð‘’ð‘Žð‘¡-ð‘ð‘–ð‘Ÿð‘ð‘™ð‘’)\n",
    "        \n",
    "        probs = []\n",
    "        for obs in sampled_states:\n",
    "            # â€–ð‘§ð‘¡ âˆ’ ð‘¥ð‘¡,ð‘–â€–ð‘”ð‘Ÿð‘’ð‘Žð‘¡-ð‘ð‘–ð‘Ÿð‘ð‘™ð‘’\n",
    "            dist_obs_roads = obs[1].Z_t_TO_X_t_i\n",
    "            \n",
    "            # ð‘(ð‘§ð‘¡|ð‘Ÿð‘–)\n",
    "            probs.append(np.exp(np.power(dist_obs_roads / self.sigma, 2) * (-0.5)) * (1 / (math.sqrt(2 * math.pi) * self.sigma)))\n",
    "\n",
    "        # Normalize result\n",
    "        if self.normalize:\n",
    "            probs = probs / np.sum(probs)\n",
    "        return probs\n",
    "    \n",
    "    def apply_transition_model(self, candidate_roads, dist_prev):\n",
    "        # TODO: simplify the code below\n",
    "        # get the beta\n",
    "        # ð›½ = 1/ln(2) mediant (|â€–ð‘§ð‘¡ âˆ’ ð‘§ð‘¡+1â€–ð‘”ð‘Ÿð‘’ð‘Žð‘¡-ð‘ð‘–ð‘Ÿð‘ð‘™ð‘’ âˆ’ â€–ð‘¥ð‘¡,ð‘–âˆ— âˆ’ð‘¥ð‘¡+1,ð‘—âˆ—â€–ð‘Ÿð‘œð‘¢ð‘¡ð‘’|)\n",
    "        \n",
    "        probs = []\n",
    "        # NOTE: â€–ð‘§ð‘¡ âˆ’ ð‘§ð‘¡+1â€–ð‘”ð‘Ÿð‘’ð‘Žð‘¡-ð‘ð‘–ð‘Ÿð‘ð‘™ð‘’ is given by dist_prev\n",
    "        for point in candidate_roads:\n",
    "            prob = []\n",
    "            for prev_point in self.prev_candidate_roads:\n",
    "                # calculate â€–ð‘¥ð‘¡,ð‘– âˆ’ ð‘¥ð‘¡+1,ð‘—â€–ð‘Ÿð‘œð‘¢ð‘¡ð‘’ \n",
    "                # TODO: need to recalculate the route\n",
    "                dist_road = great_circle_dist_x_to_z(prev_point[1].X_t_i, point[1].X_t_i)\n",
    "                \n",
    "                # TODO: terminate the search for a route when â€–ð‘¥ð‘¡,ð‘– âˆ’ ð‘¥ð‘¡+1,ð‘—â€–ð‘Ÿð‘œð‘¢ð‘¡ð‘’ \n",
    "                # becomes greater than â€–ð‘§ð‘¡ âˆ’ ð‘§ð‘¡+1â€–ð‘”ð‘Ÿð‘’ð‘Žð‘¡-ð‘ð‘–ð‘Ÿð‘ð‘™ð‘’ by 2000 meters\n",
    "                # or more, and assign a probability of zero.\n",
    "                \n",
    "                # calculate the difference between â€–ð‘§ð‘¡ âˆ’ ð‘§ð‘¡+1â€–ð‘”ð‘Ÿð‘’ð‘Žð‘¡-ð‘ð‘–ð‘Ÿð‘ð‘™ð‘’ and â€–ð‘¥ð‘¡,ð‘– âˆ’ ð‘¥ð‘¡+1,ð‘—â€–ð‘Ÿð‘œð‘¢ð‘¡ð‘’\n",
    "                diff_dist = np.abs(np.subtract(dist_road, dist_prev))\n",
    "                \n",
    "                # calculate the transition probability\n",
    "                prob.append(np.exp(-diff_dist / self.beta) * (1 / self.beta))\n",
    "                \n",
    "            probs.append(prob)\n",
    "        \n",
    "        # Normalize result?\n",
    "        if self.normalize:\n",
    "            probs = probs / np.sum(probs)\n",
    "        return probs  # the probs is a list of lists transition prob\n",
    "    \n",
    "    def update_dist(self, obs, candidate_roads, num_iter, n, max_dist2=None):\n",
    "        longitude = obs[1].longitude\n",
    "        latitude = obs[1].latitude\n",
    "        \n",
    "        # n depends on how many candidate roads you have at time t\n",
    "        self.n = n\n",
    "        \n",
    "        obs_coords = [latitude, longitude] \n",
    "        dist_prev = obs[1].dist_from_prev_m\n",
    "        \n",
    "        # transition probability\n",
    "        if num_iter > 1:\n",
    "            \n",
    "            trans_probs = self.apply_transition_model(candidate_roads, \n",
    "                                                      dist_prev) # (n * c, 1) first n rows for first candidate, etc.\n",
    "            sampled_states = candidate_roads\n",
    "#             print(\"Transition: \")\n",
    "#             print(trans_probs)\n",
    "#             print(\"--------------------------------------------------------------\")\n",
    "        else:\n",
    "            sampled_states = candidate_roads\n",
    "        \n",
    "        # emission probabilities\n",
    "        emission_probs = self.apply_emission_model(sampled_states, obs_coords) # (n, 1)\n",
    "#         print(\"Emission: \")\n",
    "#         print(emission_probs)\n",
    "#         print(\"--------------------------------------------------------------\")\n",
    "        \n",
    "        # Joint prob, for viterbi backtracking.\n",
    "        if num_iter > 1:\n",
    "            # since the num_iter is different we need to v(j)\n",
    "            max_v_list = []\n",
    "            max_v = 0\n",
    "            for i in range(len(emission_probs)):\n",
    "                for j in range(len(trans_probs[i])):\n",
    "                    # get the Recursion\n",
    "                    joint = np.multiply(self.weights[j], np.multiply(emission_probs[i], trans_probs[i][j]))\n",
    "                    if max_v < joint:\n",
    "                        max_v = joint\n",
    "                max_v_list.append(max_v)\n",
    "                max_v = 0\n",
    "#             print(\"Max_v: \")\n",
    "#             print(max_v_list)\n",
    "#             print(\"--------------------------------------------------------------\")\n",
    "            # the recursion for other states\n",
    "            joint_prob = max_v_list\n",
    "            # for other states, the prob for each road is the joint_prob\n",
    "            self.viterbi_trellis.append(joint_prob)\n",
    "            self.viterbi_list.append(candidate_roads)\n",
    "        else:\n",
    "            # the recursion for the first state\n",
    "            joint_prob = emission_probs\n",
    "            # since it is the first state, the prob for each road is the emission itself\n",
    "            self.viterbi_trellis.append(joint_prob)\n",
    "            # remember each candidate_roads place\n",
    "            self.viterbi_list.append(candidate_roads)\n",
    "            \n",
    "        # rememeber the previous recursion\n",
    "        self.weights = joint_prob\n",
    "        # remember the previous candidate_roads\n",
    "        self.prev_candidate_roads = candidate_roads\n",
    "        \n",
    "        # Estimate current particle filter fit quality of hypotheses to data; should research good metrics more.\n",
    "        fit_quality = [np.max(self.weights), np.mean(self.weights), np.median(self.weights)]\n",
    "        \n",
    "        return fit_quality\n",
    "    \n",
    "    def viterbi(self):\n",
    "        # Start with the last observation to the viterbi trellis\n",
    "        best_last_state_idx = np.argmax(self.weights)\n",
    "        backtracked_states = []\n",
    "        # Backtrack through the viterbi trellis (#obs, n, 2) actual lat/long states\n",
    "        for j in range(len(self.viterbi_trellis) - 1 , -1, -1):\n",
    "            best_last_state = self.viterbi_list[j][best_last_state_idx]\n",
    "            backtracked_states.append([best_last_state[1].StartNodeLat, best_last_state[1].StartNodeLong])\n",
    "            best_last_state_idx = np.argmax(self.viterbi_trellis[j - 1])\n",
    "        # Put in chronological order\n",
    "        backtracked_states = backtracked_states[::-1]\n",
    "        return backtracked_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b8cd2",
   "metadata": {},
   "source": [
    "# Preprocess Data & Grab the Candidate road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e864f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "def preprocess_traces(df, sigma=4.07):\n",
    "    data = df.copy()\n",
    "    data[[\"prev_latitude\", \"prev_longitude\"]] = data[[\"latitude\", \"longitude\"]].shift(-1)\n",
    "    # Ignore warning about invalid value in arcsin (nan)\n",
    "    data[\"dist_from_prev_m\"] = great_circle_dist_z_to_z(data[[\"prev_latitude\", \"prev_longitude\", \"latitude\", \"longitude\"]].values)  # 1.93 sec\n",
    "    # Take cumsum of dist\n",
    "    dist_cum = data.dist_from_prev_m.cumsum()\n",
    "    # removing points that are within 2ðœŽ of the previous included point.\n",
    "    # Select points closest to multiples of 2*sigma, in cumsum dist\n",
    "    dist_cum_idx = dist_cum // (2 * sigma)\n",
    "    filter_idx = np.subtract(dist_cum_idx, dist_cum_idx.shift(1)) == 0\n",
    "    data = data[~filter_idx]\n",
    "    \n",
    "    # seperate the route based on the occupancy\n",
    "    trips_list = []\n",
    "    trip = []\n",
    "    # for loop all the point\n",
    "    for obs in data.iterrows():\n",
    "        # if this point's occupancy is 1\n",
    "        if obs[1].occupancy == 1:\n",
    "            trip.append(obs)\n",
    "        else:\n",
    "            trips_list.append(trip)\n",
    "            trip = []\n",
    "    trips_list = [x for x in trips_list if x != []]\n",
    "    return trips_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd7df295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the Map\n",
    "def preprocess_Map(data_edge, data_node):\n",
    "    data_node.rename(columns = {'NodeID':'StartNodeID'}, inplace = True)\n",
    "    data_node.rename(columns = {'Longitude':'StartNodeLong'}, inplace = True)\n",
    "    data_node.rename(columns = {'Latitude':'StartNodeLat'}, inplace = True)\n",
    "    df_merge = pd.merge(data_edge, data_node, on=\"StartNodeID\")\n",
    "\n",
    "    data_node.rename(columns = {'StartNodeID':'EndNodeID'}, inplace = True)\n",
    "    data_node.rename(columns = {'StartNodeLong':'EndNodeLong'}, inplace = True)\n",
    "    data_node.rename(columns = {'StartNodeLat':'EndNodeLat'}, inplace = True)\n",
    "    df_merge = pd.merge(df_merge, data_node, on=\"EndNodeID\")\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160623ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the candidate road\n",
    "# TODO: \n",
    "# Since we know we are tracking ordinary vehicles on public streets, if a \n",
    "# calculated route would require the vehicle to exceed a speed of 50 m/s \n",
    "# (112 miles per hour, 180 kilometers per hour), or travel in excess of \n",
    "# three times the posted speed limit, we consider the route to be unreasonable,\n",
    "# and set its probability to zero.\n",
    "\n",
    "def get_candidate_roads(Map, data):\n",
    "    # [candidate road for time 0, candidate road for time 1,....]\n",
    "    candidate_roads = [] \n",
    "    # let's get the candidate roads for each time t\n",
    "    for obs in data:\n",
    "        # get the lat and long for the point\n",
    "        z_long = obs[1].longitude\n",
    "        z_lat = obs[1].latitude\n",
    "        z = [z_lat, z_long]\n",
    "        # match the coords and the dataset\n",
    "        candidate_road = []\n",
    "        for edge in Map.iterrows():\n",
    "            p1 = np.array([edge[1].StartNodeLat, edge[1].StartNodeLong])\n",
    "            p2 = np.array([edge[1].EndNodeLat, edge[1].EndNodeLong])\n",
    "            p3 = np.array(z)\n",
    "            \n",
    "            # ð‘¥ð‘¡,ð‘–: the perpendicular point from the z to the road \n",
    "            x_t_i = get_perpendicular_point(p3, (p1, p2))\n",
    "            \n",
    "            # check if ð‘¥ð‘¡,ð‘– is on the line\n",
    "            dist_p1_x = great_circle_dist_x_to_z(p1, x_t_i)\n",
    "            dist_p2_x = great_circle_dist_x_to_z(p2, x_t_i)\n",
    "            dist_p1_p2 = great_circle_dist_x_to_z(p1, p2)\n",
    "            \n",
    "            if ((dist_p1_x + dist_p2_x) - dist_p1_p2)/2 > 200:\n",
    "                continue\n",
    "            \n",
    "            # calculate the distance from the point to the road\n",
    "            d = great_circle_dist_x_to_z(p3, x_t_i)\n",
    "            \n",
    "            # Any road segment more than 200 meters away from the GPS point.\n",
    "            if d < 200:\n",
    "#                 print(p1)\n",
    "#                 print(p2)\n",
    "#                 print(p3)\n",
    "#                 print(x_t_i)\n",
    "                edge[1]['X_t_i'] = x_t_i\n",
    "                edge[1]['Z_t_TO_X_t_i'] = d\n",
    "                edge[1]['Z_t_TO_Z_t1'] = obs[1].dist_from_prev_m\n",
    "                candidate_road.append(edge)\n",
    "                \n",
    "        # TODO: When a break is detected between time step ð‘¡ and time step ð‘¡ + 1, \n",
    "        # we remove measured points ð‘§ð‘¡ and ð‘§ð‘¡+1 from the model, and check to see \n",
    "        # if the break has been healed. The break is considered healed if the \n",
    "        # measured points at ð‘¡ âˆ’ 1 and ð‘¡ + 2 lead to a reconnection in the HMM \n",
    "        # after rechecking the points with the bulleted conditions above. If the \n",
    "        # break is still present, we continue to remove the points on either side \n",
    "        # of the break until either the break is healed, or the break is more than \n",
    "        # 180 seconds long. \n",
    "        if len(candidate_road) == 0:\n",
    "            print(\"No matching roads found within max road distance! Aborting particle filter.\")\n",
    "            return None\n",
    "        candidate_roads.append(candidate_road)\n",
    "    return candidate_roads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4e6ba",
   "metadata": {},
   "source": [
    "# Load the Data and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5e0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training path\n",
    "train_path = '/Users/richard/Downloads/for_student/training'\n",
    "# Node_path = '/Users/richard/Downloads/for_student/road_network_in_CA/node.txt'\n",
    "# Edge_path = '/Users/richard/Downloads/for_student/road_network_in_CA/edge.txt'\n",
    "node_path = '/Users/richard/Downloads/for_student/Map.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e0d658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the Map\n",
    "# data_edge = pd.read_csv(Edge_path, sep=' ')\n",
    "# data_node = pd.read_csv(Node_path, sep=' ')\n",
    "\n",
    "Map = pd.read_csv(node_path, sep=' ')\n",
    "\n",
    "# Map = preprocess_Map(data_edge, data_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66b8225c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all the files in the training folder\n",
    "all_files = [f for f in os.listdir(train_path)]\n",
    "\n",
    "# read the 1st file in the folder as a test case\n",
    "train_df = pd.read_csv(os.path.join(train_path, all_files[0]), sep=\" \", index_col=None, header=None, \n",
    "                      names=['latitude', 'longitude', 'occupancy', 'time'])\n",
    "\n",
    "# convert the time from unix into date time\n",
    "train_df.loc[:, [\"time\"]] = pd.to_datetime(train_df.time, origin=\"unix\", unit='s')\n",
    "\n",
    "# preprocess the data\n",
    "trips_list = preprocess_traces(train_df)\n",
    "\n",
    "\n",
    "# pick one trip for HMM training\n",
    "# [0, 1, 129, 130, 131, 132, 133, 134, 135]\n",
    "trip = trips_list[131]\n",
    "\n",
    "# get the candidate roads\n",
    "candidate_roads = get_candidate_roads(Map, trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15985eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 1, fit quality of MAX 1.00, MEAN 1.00, MEDIAN 1.00\n",
      "On iteration 2, fit quality of MAX 1.00, MEAN 1.00, MEDIAN 1.00\n",
      "On iteration 3, fit quality of MAX 0.99, MEAN 0.49, MEDIAN 0.49\n",
      "On iteration 4, fit quality of MAX 0.00, MEAN 0.00, MEDIAN 0.00\n",
      "On iteration 5, fit quality of MAX 0.00, MEAN 0.00, MEDIAN 0.00\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "model = HMMModel()\n",
    "\n",
    "# training\n",
    "def train(data, candidate_roads):\n",
    "    data = data.copy()\n",
    "    num_iter = 0\n",
    "    converged = False\n",
    "    for obs in data:\n",
    "        num_iter += 1\n",
    "        fit_quality = model.update_dist(obs, candidate_roads[num_iter-1], num_iter, len(candidate_roads[num_iter-1]))\n",
    "        if fit_quality == \"Aborted\":\n",
    "            return \"Aborted\"\n",
    "        print(\"On iteration %d, fit quality of MAX %3.2f, MEAN %3.2f, MEDIAN %3.2f\" % \n",
    "              (num_iter, fit_quality[0], fit_quality[1], fit_quality[2]))\n",
    "    print(\"Done.\")\n",
    "\n",
    "train(trip, candidate_roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3188e46",
   "metadata": {},
   "source": [
    "# Get the result from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2d54f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37.7866, -122.4149], [37.7866, -122.4149], [37.7861, -122.4179], [37.7861, -122.4179], [37.7806, -122.4169]]\n"
     ]
    }
   ],
   "source": [
    "backtracked_trace = model.viterbi()\n",
    "print(backtracked_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7eeccb",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fadf3171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37.78634, -122.41464], [37.78632, -122.41474], [37.78511, -122.41789], [37.78122, -122.41717], [37.78075, -122.41538]]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"37.7805264 -122.4181136 0.006037200000001519 0.00369719999999063\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,-244.83253000000002)\"><polyline fill=\"none\" stroke=\"#66cc99\" stroke-width=\"0.00012074400000003038\" points=\"37.78634,-122.41464 37.78632,-122.41474 37.78511,-122.41789 37.78122,-122.41717 37.78075,-122.41538\" opacity=\"0.8\" /></g></svg>"
      ],
      "text/plain": [
       "<LINESTRING (37.786 -122.415, 37.786 -122.415, 37.785 -122.418, 37.781 -122....>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(trip[1].latitdue)\n",
    "trip_list = []\n",
    "for point in trip:\n",
    "    trip_list.append([point[1].latitude, point[1].longitude])\n",
    "print(trip_list)\n",
    "LineString(trip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b26c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37.7866, -122.4149], [37.7866, -122.4149], [37.7861, -122.4179], [37.7861, -122.4179], [37.7806, -122.4169]]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"37.78036 -122.41814000000001 0.0064799999999962665 0.0034800000000103637\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,-244.83280000000002)\"><polyline fill=\"none\" stroke=\"#66cc99\" stroke-width=\"0.00012959999999992533\" points=\"37.7866,-122.4149 37.7866,-122.4149 37.7861,-122.4179 37.7861,-122.4179 37.7806,-122.4169\" opacity=\"0.8\" /></g></svg>"
      ],
      "text/plain": [
       "<LINESTRING (37.787 -122.415, 37.787 -122.415, 37.786 -122.418, 37.786 -122....>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_list = []\n",
    "for point in backtracked_trace:\n",
    "    trip_list.append([point[0], point[1]])\n",
    "print(trip_list)\n",
    "LineString(trip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cae5383",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    StartNodeLat  StartNodeLong  EndNodeLat  EndNodeLong\n",
      "0        37.7841      -122.3986     37.7838    -122.3989\n",
      "1        37.7838      -122.3989     37.7850    -122.4005\n",
      "2        37.7850      -122.4005     37.7862    -122.4020\n",
      "3        37.7862      -122.4020     37.7875    -122.4034\n",
      "4        37.7875      -122.4034     37.7879    -122.4035\n",
      "..           ...            ...         ...          ...\n",
      "88       37.7857      -122.4064     37.7855    -122.4079\n",
      "89       37.7855      -122.4079     37.7849    -122.4078\n",
      "90       37.7866      -122.4149     37.7861    -122.4179\n",
      "91       37.7861      -122.4179     37.7806    -122.4169\n",
      "92       37.7806      -122.4169     37.7807    -122.4153\n",
      "\n",
      "[93 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wd/z38sgpjj2yx5qdc96wz1cdn80000gn/T/ipykernel_67876/1761750590.py:8: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated infavour of `both` or `neither`.\n",
      "  df_node_SF = Map[Map['StartNodeLong'].between(-122.524, -122.345, inclusive=True)]\n",
      "/var/folders/wd/z38sgpjj2yx5qdc96wz1cdn80000gn/T/ipykernel_67876/1761750590.py:9: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated infavour of `both` or `neither`.\n",
      "  df_node_SF = df_node_SF[df_node_SF['StartNodeLat'].between(37.702, 37.812, inclusive=True)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_05b5a4662cebd3fe1a8e862e1ff2b252 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_05b5a4662cebd3fe1a8e862e1ff2b252&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_05b5a4662cebd3fe1a8e862e1ff2b252 = L.map(\n",
       "                &quot;map_05b5a4662cebd3fe1a8e862e1ff2b252&quot;,\n",
       "                {\n",
       "                    center: [37.759457, -122.444781],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 12,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: true,\n",
       "                }\n",
       "            );\n",
       "            L.control.scale().addTo(map_05b5a4662cebd3fe1a8e862e1ff2b252);\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_d4640fe71b7b9a15b7da65513679f760 = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_05b5a4662cebd3fe1a8e862e1ff2b252);\n",
       "        \n",
       "    \n",
       "            var feature_group_3cac17b2520e53e522cd815ed814e3e5 = L.featureGroup(\n",
       "                {}\n",
       "            ).addTo(map_05b5a4662cebd3fe1a8e862e1ff2b252);\n",
       "        \n",
       "    \n",
       "            var poly_line_a93c82a25556fe4eb00067dd3062c6a7 = L.polyline(\n",
       "                [[37.7866, -122.4149], [37.7866, -122.4149]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;Green&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;Green&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(feature_group_3cac17b2520e53e522cd815ed814e3e5);\n",
       "        \n",
       "    \n",
       "            var poly_line_b76fbdcede0aeaa9da3b76d3f1dfca27 = L.polyline(\n",
       "                [[37.7866, -122.4149], [37.7861, -122.4179]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;Green&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;Green&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(feature_group_3cac17b2520e53e522cd815ed814e3e5);\n",
       "        \n",
       "    \n",
       "            var poly_line_79820d40154b2ce7234c5f1694e68b0d = L.polyline(\n",
       "                [[37.7861, -122.4179], [37.7861, -122.4179]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;Green&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;Green&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(feature_group_3cac17b2520e53e522cd815ed814e3e5);\n",
       "        \n",
       "    \n",
       "            var poly_line_3c072da5b64aa4f9b9e4cc6ccf842d89 = L.polyline(\n",
       "                [[37.7861, -122.4179], [37.7806, -122.4169]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;Green&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;Green&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(feature_group_3cac17b2520e53e522cd815ed814e3e5);\n",
       "        \n",
       "    \n",
       "            var feature_group_793eefcc46a5fb40630690c6f1b1f498 = L.featureGroup(\n",
       "                {}\n",
       "            ).addTo(map_05b5a4662cebd3fe1a8e862e1ff2b252);\n",
       "        \n",
       "    \n",
       "            var poly_line_adaa62e78331f115cd5a62a4d172f1de = L.polyline(\n",
       "                [[37.78632, -122.41474], [37.78634, -122.41464]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;Blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;Blue&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(feature_group_793eefcc46a5fb40630690c6f1b1f498);\n",
       "        \n",
       "    \n",
       "            var poly_line_3e94b33c57df5dc1e6602fa3217c9595 = L.polyline(\n",
       "                [[37.78511, -122.41789], [37.78632, -122.41474]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;Blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;Blue&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(feature_group_793eefcc46a5fb40630690c6f1b1f498);\n",
       "        \n",
       "    \n",
       "            var poly_line_7ba472c33cf964f7fc103535ce583854 = L.polyline(\n",
       "                [[37.78122, -122.41717], [37.78511, -122.41789]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;Blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;Blue&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(feature_group_793eefcc46a5fb40630690c6f1b1f498);\n",
       "        \n",
       "    \n",
       "            var poly_line_a73623ce3e3ececdba47f2befe7dad51 = L.polyline(\n",
       "                [[37.78075, -122.41538], [37.78122, -122.41717]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;Blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;Blue&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(feature_group_793eefcc46a5fb40630690c6f1b1f498);\n",
       "        \n",
       "    \n",
       "            var poly_line_977393d67e6e81fa1def146a288a4ace = L.polyline(\n",
       "                [[37.78084, -122.4153], [37.78075, -122.41538]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;Blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;Blue&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1.0, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(feature_group_793eefcc46a5fb40630690c6f1b1f498);\n",
       "        \n",
       "    \n",
       "            var layer_control_c889da401a53a45e4774ff95aede0733 = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_d4640fe71b7b9a15b7da65513679f760,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Matched Roads&quot; : feature_group_3cac17b2520e53e522cd815ed814e3e5,\n",
       "                    &quot;One Trip for HMM Training&quot; : feature_group_793eefcc46a5fb40630690c6f1b1f498,\n",
       "                },\n",
       "            };\n",
       "            L.control.layers(\n",
       "                layer_control_c889da401a53a45e4774ff95aede0733.base_layers,\n",
       "                layer_control_c889da401a53a45e4774ff95aede0733.overlays,\n",
       "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
       "            ).addTo(map_05b5a4662cebd3fe1a8e862e1ff2b252);\n",
       "        \n",
       "    \n",
       "                var lat_lng_popup_dca313d57839f9ed1bbbbfe366694d35 = L.popup();\n",
       "                function latLngPop(e) {\n",
       "                    lat_lng_popup_dca313d57839f9ed1bbbbfe366694d35\n",
       "                        .setLatLng(e.latlng)\n",
       "                        .setContent(&quot;Latitude: &quot; + e.latlng.lat.toFixed(4) +\n",
       "                                    &quot;&lt;br&gt;Longitude: &quot; + e.latlng.lng.toFixed(4))\n",
       "                        .openOn(map_05b5a4662cebd3fe1a8e862e1ff2b252);\n",
       "                    }\n",
       "                map_05b5a4662cebd3fe1a8e862e1ff2b252.on(&#x27;click&#x27;, latLngPop);\n",
       "            \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7faee5e63490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libraries for map visualization\n",
    "\n",
    "import networkx as nx\n",
    "import folium\n",
    "\n",
    "# Add the standard road network\n",
    "\n",
    "df_node_SF = Map[Map['StartNodeLong'].between(-122.524, -122.345, inclusive=True)]\n",
    "df_node_SF = df_node_SF[df_node_SF['StartNodeLat'].between(37.702, 37.812, inclusive=True)]\n",
    "df_node_SF.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Add the matched roads\n",
    "matched_fg = folium.FeatureGroup(name='Matched Roads')\n",
    "\n",
    "for i in range(len(trip_list)):\n",
    "\n",
    "    # Draw traces\n",
    "    if i < len(trip_list)-1:\n",
    "        traces = folium.PolyLine(locations=[trip_list[i], trip_list[i+1]], weight=3, color='Green')\n",
    "    \n",
    "    # Add the polyline to the feature group\n",
    "    matched_fg.add_child(traces)\n",
    "\n",
    "# Trip picked for HMM Training\n",
    "trip_fg = folium.FeatureGroup(name='One Trip for HMM Training')\n",
    "\n",
    "\n",
    "for i in range(len(trip)):\n",
    "\n",
    "    # Draw traces\n",
    "    current_coord = [trip[i][1][0], trip[i][1][1]]\n",
    "    previous_coord = [trip[i][1][4], trip[i][1][5]]\n",
    "    traces = folium.PolyLine(locations=[previous_coord, current_coord], weight=3, color='Blue')\n",
    "\n",
    "    # Add to the feature group\n",
    "    trip_fg.add_child(traces)\n",
    "\n",
    "\n",
    "# Create a map centered at San Francisco\n",
    "sf_map = folium.Map(location=[37.759457, -122.444781], zoom_start=12, prefer_canvas=True, control_scale=True)\n",
    "\n",
    "# Add the feature groups to the map\n",
    "# sf_map.add_child(network_fg)\n",
    "sf_map.add_child(matched_fg)\n",
    "sf_map.add_child(trip_fg)\n",
    "\n",
    "# Add a layer control feature\n",
    "folium.LayerControl().add_to(sf_map)\n",
    "\n",
    "# Add click for coords feature\n",
    "sf_map.add_child(folium.LatLngPopup())\n",
    "\n",
    "# save map\n",
    "#sf_map.save('SF_MAP.html')\n",
    "\n",
    "# display map\n",
    "sf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6584e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
