{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501c5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stage 1: Map Matching\n",
    "\n",
    "### In Stage 1, the main task is to map all the trajectories to road segments. \n",
    "### The basic process will be similar to what we discuss about the HMM paper, \n",
    "### but feel free to come to with any “crazy” ideas. (optional)\n",
    "### Also, think about how you will evaluate the results.\n",
    "\n",
    "### **Input**: trajectories, \n",
    "\n",
    "### **Output**: each GPS point should have one corresponding matched road segment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16045bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "import os, sys\n",
    "import math\n",
    "from shapely.geometry import shape, Point, LineString, MultiLineString\n",
    "from sklearn.metrics.pairwise import haversine_distances \n",
    "\n",
    "\n",
    "RADIUS_OF_EARTH_M = 6371000\n",
    "MILES_PER_METER = 0.000621371\n",
    "HOURS_PER_SECOND = 3600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6127239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# great circle distance\n",
    "def Euclidean_distance(latitude, longitude, prev_latitude, prev_longitude):\n",
    "    # convert decimal degrees to radians \n",
    "    \n",
    "    dlon = longitude - prev_longitude # lon2 - lon1 \n",
    "    dlat = latitude - prev_latitude # lat2 - lat1 \n",
    "    \n",
    "    return np.sqrt(dlon**2 + dlat**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570315fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# great circle distance \n",
    "def great_circle_dist(df):\n",
    "    # convert decimal degrees to radians \n",
    "    df = df.copy()\n",
    "    df = np.deg2rad(df)\n",
    "    \n",
    "    longitude = df[:, 3]\n",
    "    latitude = df[:, 2]\n",
    "    prev_longitude = df[:, 1]\n",
    "    prev_latitude = df[:, 0]\n",
    "    \n",
    "    # haversine formula \n",
    "    dlon = longitude - prev_longitude # lon2 - lon1 \n",
    "    dlat = latitude - prev_latitude # lat2 - lat1 \n",
    "    \n",
    "    # a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    a = np.add(np.square(np.sin(dlat / 2)),\n",
    "               np.multiply(np.cos(prev_latitude), \n",
    "                           np.multiply(np.cos(latitude), np.square(np.sin(dlon / 2)))\n",
    "                          )\n",
    "              )\n",
    "    \n",
    "    # c = 2 * asin(sqrt(a)) \n",
    "    c = np.arcsin(np.sqrt(a)) * 2\n",
    "    \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return r * c * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dbead9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minDistance(A, B, E) :\n",
    " \n",
    "    # vector AB\n",
    "    AB = [None, None];\n",
    "    AB[0] = B[0] - A[0];\n",
    "    AB[1] = B[1] - A[1];\n",
    " \n",
    "    # vector BE\n",
    "    BE = [None, None];\n",
    "    BE[0] = E[0] - B[0];\n",
    "    BE[1] = E[1] - B[1];\n",
    " \n",
    "    # vector AE\n",
    "    AE = [None, None];\n",
    "    AE[0] = E[0] - A[0];\n",
    "    AE[1] = E[1] - A[1];\n",
    " \n",
    "    # Variables to store dot product\n",
    " \n",
    "    # Calculating the dot product\n",
    "    AB_BE = AB[0] * BE[0] + AB[1] * BE[1];\n",
    "    AB_AE = AB[0] * AE[0] + AB[1] * AE[1];\n",
    " \n",
    "    # Minimum distance from\n",
    "    # point E to the line segment\n",
    "    reqAns = 0;\n",
    " \n",
    "    # Case 1\n",
    "    if (AB_BE > 0) :\n",
    " \n",
    "        # Finding the magnitude\n",
    "        y = E[1] - B[1];\n",
    "        x = E[0] - B[0];\n",
    "        reqAns = math.sqrt(x * x + y * y);\n",
    " \n",
    "    # Case 2\n",
    "    elif (AB_AE < 0) :\n",
    "        y = E[1] - A[1];\n",
    "        x = E[0] - A[0];\n",
    "        reqAns = math.sqrt(x * x + y * y);\n",
    " \n",
    "    # Case 3\n",
    "    else:\n",
    " \n",
    "        # Finding the perpendicular distance\n",
    "        x1 = AB[0];\n",
    "        y1 = AB[1];\n",
    "        x2 = AE[0];\n",
    "        y2 = AE[1];\n",
    "        mod = math.sqrt(x1 * x1 + y1 * y1);\n",
    "        reqAns = abs(x1 * y2 - y1 * x2) / mod;\n",
    "    return reqAns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ce707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HMM model\n",
    "class HMMModel(nn.Module):\n",
    "    def __init__(self, sigma = 4.07, beta=3.0, normalize=True, \n",
    "                 prob_floor=0.0, n = 0, viterbi_trellis=[], prev_candidate_roads = []):\n",
    "        self.sigma = sigma\n",
    "        self.beta = beta\n",
    "        self.normalize = normalize\n",
    "        self.prob_floor = min(max(prob_floor, 0), 1)\n",
    "        self.obs_history = []\n",
    "        self.n = n\n",
    "        self.weights = np.zeros((1, self.n))\n",
    "        self.particles = np.array([])\n",
    "        self.viterbi_trellis = viterbi_trellis  # list of particle np arrays\n",
    "        self.prev_candidate_roads = prev_candidate_roads\n",
    "#         self.viterbi_trellis_idx = viterbi_trellis_idx  # list of np arrays, columns candidate road indices, particle indices\n",
    "      \n",
    "    # TODO?: get the 𝑥𝑡,𝑖 (the perpendicular point from the trip point to the road segments)\n",
    "    def apply_emission_model(self, sampled_states, obs_coords):\n",
    "        probs = []\n",
    "        for obs in sampled_states:\n",
    "            # ‖𝑧𝑡 − 𝑥𝑡,𝑖‖𝑔𝑟𝑒𝑎𝑡-𝑐𝑖𝑟𝑐𝑙𝑒\n",
    "            dist_obs_roads = obs[1].ShortestDistance\n",
    "            \n",
    "            # 𝑝(𝑧𝑡|𝑟𝑖)\n",
    "            probs.append(np.exp(np.power(dist_obs_roads / self.sigma, 2) * (-0.5)) * (1 / (math.sqrt(2 * math.pi) * self.sigma)))\n",
    "\n",
    "        # Normalize result\n",
    "        # TODO: Answer the question: Why do we need to normalize\n",
    "        if self.normalize:\n",
    "            probs = probs / np.sum(probs)\n",
    "        return probs\n",
    "    \n",
    "    def apply_transition_model(self, candidate_roads, dist_prev):\n",
    "        # TODO: terminate the search for a route when ‖𝑥𝑡,𝑖 − 𝑥𝑡+1,𝑗‖𝑟𝑜𝑢𝑡𝑒 \n",
    "        # becomes greater than ‖𝑧𝑡 − 𝑧𝑡+1‖𝑔𝑟𝑒𝑎𝑡-𝑐𝑖𝑟𝑐𝑙𝑒 by 2000 meters\n",
    "        # or more, and assign a probability of zero.\n",
    "        probs = []\n",
    "        # go through the candidate_roads and check the distance with the previous candidate_roads\n",
    "        #\n",
    "        # O -> 1\n",
    "        # O -> 1\n",
    "        # O -> 1\n",
    "        # O -> 1\n",
    "        # NOTE: ‖𝑧𝑡 − 𝑧𝑡+1‖𝑔𝑟𝑒𝑎𝑡-𝑐𝑖𝑟𝑐𝑙𝑒 is given by dist_prev\n",
    "        for point in candidate_roads:\n",
    "            prob = []\n",
    "            for prev_point in self.prev_candidate_roads:\n",
    "                # calculate ‖𝑥𝑡,𝑖 − 𝑥𝑡+1,𝑗‖𝑟𝑜𝑢𝑡𝑒\n",
    "                # TODO: calculate the distance with the perpendicular point\n",
    "                dist_road = Euclidean_distance(point[1].StartNodeLat, point[1].StartNodeLong, prev_point[1].StartNodeLat, prev_point[1].StartNodeLong)\n",
    "                \n",
    "                # calculate the difference between ‖𝑧𝑡 − 𝑧𝑡+1‖𝑔𝑟𝑒𝑎𝑡-𝑐𝑖𝑟𝑐𝑙𝑒 and ‖𝑥𝑡,𝑖 − 𝑥𝑡+1,𝑗‖𝑟𝑜𝑢𝑡𝑒\n",
    "                diff_dist = np.abs(np.subtract(dist_road, dist_prev))\n",
    "                \n",
    "                # calculate the transition probability\n",
    "                prob.append(np.exp(-diff_dist / self.beta) * (1 / self.beta))\n",
    "            probs.append(prob)\n",
    "        \n",
    "        # Normalize result?\n",
    "        # TODO: Answer the question: Why do we need to normalize\n",
    "        if self.normalize:\n",
    "            probs = probs / np.sum(probs)\n",
    "        return probs  # the probs is a list of lists transition prob\n",
    "    \n",
    "    def update_dist(self, obs, candidate_roads, num_iter, total_num, max_dist2=None):\n",
    "        self.n = total_num\n",
    "        longitude = obs[1].longitude\n",
    "        latitude = obs[1].latitude\n",
    "        dist_from_prev_m = obs[1].dist_from_prev_m\n",
    "        \n",
    "        obs_coords = [latitude, longitude] \n",
    "        dist_prev = dist_from_prev_m\n",
    "        self.obs_history.append(obs_coords)\n",
    "        \n",
    "        # transition probability\n",
    "        if num_iter > 1:\n",
    "            trans_probs = self.apply_transition_model(candidate_roads, \n",
    "                                                      dist_prev) # (n * c, 1) first n rows for first candidate, etc.\n",
    "            # Aggregate probs by candidate roads\n",
    "            for trans_prob in trans_probs:\n",
    "                print(trans_prob)\n",
    "                print(self.weights)\n",
    "                print(np.multiply(trans_prob, self.weights))\n",
    "                return \"Aborted\"\n",
    "#             trans_probs_agg = np.sum(trans_probs)\n",
    "#             print(trans_probs_agg)\n",
    "            \n",
    "            trans_probs_split = np.array(np.split(trans_probs, self.n, axis=0))  # (n, c, 1)\n",
    "            trans_probs_agg = np.sum(trans_probs_split, axis=0)  # (c, 1)\n",
    "            \n",
    "            # Sample new states\n",
    "            # Sample new states; index into candidate roads\n",
    "            sampled_states_idx = np.random.choice(range(len(candidate_roads)), \n",
    "                                                  self.n, \n",
    "                                                  list(trans_probs_agg.flatten()))  # (n, )\n",
    "            sampled_states = []\n",
    "            for i in range(len(sampled_states_idx)):\n",
    "                sampled_states.append(candidate_roads[sampled_states_idx[i]])  # (n, 2)\n",
    "            # alph𝑡(i)\n",
    "            sampled_states_best_prior = np.argmax(sampled_states_idx)  # (n, 1)\n",
    "#             sampled_states_best_prior = sampled_states_idx.reshape(-1, 1)\n",
    "\n",
    "            return \"Aborted\"\n",
    "        else:\n",
    "            sampled_states = candidate_roads\n",
    "            # alph𝑡(i) when t = 0\n",
    "            sampled_states_best_prior = 1\n",
    "        \n",
    "        # emission probabilities\n",
    "        emission_probs = self.apply_emission_model(sampled_states, obs_coords)  # (n, 1) \n",
    "        \n",
    "        \n",
    "        # Joint prob, for viterbi backtracking. Do this in the log domain.  \n",
    "        if num_iter > 1:\n",
    "            # May want to do this in the log domain?\n",
    "            joint_prob = np.add(\n",
    "                np.add(np.log(sensor_probs), np.max(np.log(trans_probs_split), axis=0)[sampled_states_idx]),  # (n, 1)\n",
    "                self.weights\n",
    "                )\n",
    "        \n",
    "        # the initial state probability 𝜋𝑖\n",
    "        new_particles = emission_probs * sampled_states_best_prior\n",
    "#         index = np.where(new_particles == np.max(new_particles))[0][0]\n",
    "    \n",
    "        # Best prior state/particle for a given candidate state, for viterbi backtracking. \n",
    "        if num_iter > 1:\n",
    "            # find the maximum road segment\n",
    "            # viterbi_trellis = candidate_roads[np.where(new_particles == np.max(new_particles))[0][0]]\n",
    "            viterbi_trellis_list = []\n",
    "            for probs in new_particles:\n",
    "                viterbi_trellis_list.append([obs[1].StartNodeLat, obs[1].StartNodeLong])\n",
    "                \n",
    "            self.viterbi_trellis.append(viterbi_trellis_list)\n",
    "            self.viterbi_trellis_idx.append(sampled_states_best_prior)\n",
    "        else:\n",
    "            self.viterbi_trellis.append(new_particles)\n",
    "            joint_prob = new_particles  # Initialization probability\n",
    "        \n",
    "        self.weights = joint_prob\n",
    "        \n",
    "        self.prev_candidate_roads = candidate_roads\n",
    "        \n",
    "        self.particles = new_particles\n",
    "        \n",
    "        # Estimate current particle filter fit quality of hypotheses to data; should research good metrics more.\n",
    "        fit_quality = [np.max(self.weights), np.mean(self.weights), np.median(self.weights)]\n",
    "        \n",
    "        return fit_quality\n",
    "    \n",
    "    def viterbi(self):\n",
    "        # Start with the last observation to the viterbi trellis\n",
    "        best_last_state_idx = np.argmax(self.weights)\n",
    "        backtracked_states = []\n",
    "        # Backtrack through the viterbi trellis (#obs, n, 2) actual lat/long states\n",
    "        for j in range(len(self.viterbi_trellis) - 1):\n",
    "            # for that 'candidate road,' the particle index (col 1)\n",
    "            best_last_state = self.viterbi_trellis[j][best_last_state_idx]\n",
    "            best_last_state_idx = self.viterbi_trellis_idx[j]\n",
    "            backtracked_states.append(best_last_state)\n",
    "        # Put in chronological order\n",
    "        backtracked_states = backtracked_states[::-1]\n",
    "        return backtracked_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e864f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "def preprocess_traces(df, sigma=4.07):\n",
    "    data = df.copy()\n",
    "    data[[\"prev_latitude\", \"prev_longitude\"]] = data[[\"latitude\", \"longitude\"]].shift(1)\n",
    "    # Ignore warning about invalid value in arcsin (nan)\n",
    "    data[\"dist_from_prev_m\"] = great_circle_dist(data[[\"prev_latitude\", \"prev_longitude\", \"latitude\", \"longitude\"]].values)  # 1.93 sec\n",
    "    # Take cumsum of dist\n",
    "    dist_cum = data.dist_from_prev_m.cumsum()\n",
    "    # Select points closest to multiples of 2*sigma, in cumsum dist\n",
    "    dist_cum_idx = dist_cum // (2 * sigma)\n",
    "    filter_idx = np.subtract(dist_cum_idx, dist_cum_idx.shift(1)) == 0  # 12% of rows eliminated \n",
    "    data = data[~filter_idx]\n",
    "    \n",
    "    # seperate the route based on the occupancy\n",
    "    trips_list = []\n",
    "    trip = []\n",
    "    # for loop all the point\n",
    "    for obs in data.iterrows():\n",
    "        # if this point's occupancy is 1\n",
    "        if obs[1].occupancy == 1:\n",
    "            trip.append(obs)\n",
    "        else:\n",
    "            trips_list.append(trip)\n",
    "            trip = []\n",
    "    trips_list = [x for x in trips_list if x != []]\n",
    "    return trips_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7df295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the Map\n",
    "def preprocess_Map(data_edge, data_node):\n",
    "    data_node.rename(columns = {'NodeID':'StartNodeID'}, inplace = True)\n",
    "    data_node.rename(columns = {'Longitude':'StartNodeLong'}, inplace = True)\n",
    "    data_node.rename(columns = {'Latitude':'StartNodeLat'}, inplace = True)\n",
    "    df_merge = pd.merge(data_edge, data_node, on=\"StartNodeID\")\n",
    "\n",
    "    data_node.rename(columns = {'StartNodeID':'EndNodeID'}, inplace = True)\n",
    "    data_node.rename(columns = {'StartNodeLong':'EndNodeLong'}, inplace = True)\n",
    "    data_node.rename(columns = {'StartNodeLat':'EndNodeLat'}, inplace = True)\n",
    "    df_merge = pd.merge(df_merge, data_node, on=\"EndNodeID\")\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5e0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training path\n",
    "train_path = './training'\n",
    "Node_path = './road network in CA/node.txt'\n",
    "Edge_path = './road network in CA/edge.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e0d658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z1297\\AppData\\Local\\Temp\\ipykernel_8840\\296047548.py:9: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  df_node_SF = Map[Map['StartNodeLong'].between(-122.524, -122.345, inclusive=True)]\n",
      "C:\\Users\\z1297\\AppData\\Local\\Temp\\ipykernel_8840\\296047548.py:10: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  df_node_SF = df_node_SF[df_node_SF['StartNodeLat'].between(37.702, 37.812, inclusive=True)]\n"
     ]
    }
   ],
   "source": [
    "# get the Map\n",
    "data_edge = pd.read_csv(Edge_path, sep=' ')\n",
    "data_node = pd.read_csv(Node_path, sep=' ')\n",
    "\n",
    "# create map\n",
    "Map = preprocess_Map(data_edge, data_node)\n",
    "\n",
    "# create SF roads df\n",
    "df_node_SF = Map[Map['StartNodeLong'].between(-122.524, -122.345, inclusive=True)]\n",
    "df_node_SF = df_node_SF[df_node_SF['StartNodeLat'].between(37.702, 37.812, inclusive=True)]\n",
    "df_node_SF.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b8225c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all the files in the training folder\n",
    "all_files = [f for f in os.listdir(train_path)]\n",
    "\n",
    "# read the 1st file in the folder as a test case\n",
    "train_df = pd.read_csv(os.path.join(train_path, all_files[1]), sep=\" \", index_col=None, header=None, \n",
    "                      names=['latitude', 'longitude', 'occupancy', 'time'])\n",
    "\n",
    "# convert the time from unix into date time\n",
    "train_df.loc[:, [\"time\"]] = pd.to_datetime(train_df.time, origin=\"unix\", unit='s')\n",
    "\n",
    "# preprocess the data\n",
    "trips_list = preprocess_traces(train_df)\n",
    "\n",
    "# pick one trip for HMM training\n",
    "trip = trips_list[4]\n",
    "\n",
    "# replace the great circle distance with the euclidean distance\n",
    "for x in trip:\n",
    "    x[1].dist_from_prev_m = Euclidean_distance(x[1].latitude, x[1].longitude, x[1].prev_latitude, x[1].prev_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "160623ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the candidate road\n",
    "# TODO: \n",
    "# Since we know we are tracking ordinary vehicles on public streets, if a \n",
    "# calculated route would require the vehicle to exceed a speed of 50 m/s \n",
    "# (112 miles per hour, 180 kilometers per hour), or travel in excess of \n",
    "# three times the posted speed limit, we consider the route to be unreasonable,\n",
    "# and set its probability to zero.\n",
    "def get_candidate_roads(Map, data):\n",
    "    # [candidate road for time 0, candidate road for time 1,....]\n",
    "    candidate_roads = [] \n",
    "    # let's get the candidate roads for each time t\n",
    "    for obs in data:\n",
    "        # get the lat and long for the point\n",
    "        z_long = obs[1].longitude\n",
    "        z_lat = obs[1].latitude\n",
    "        z = [z_lat, z_long]\n",
    "        # match the coords and the dataset\n",
    "        candidate_road = []\n",
    "        for edge in Map.iterrows():\n",
    "            p1 = np.array([edge[1].StartNodeLat, edge[1].StartNodeLong])\n",
    "            p2 = np.array([edge[1].EndNodeLat, edge[1].EndNodeLong])\n",
    "            p3 = np.array(z)\n",
    "            # calculate the distance from the point to the road\n",
    "            # TODO: convert this euclidance distance to the Great Circle\n",
    "            d = minDistance(p1, p2, p3)\n",
    "            # different\n",
    "            # e = np.linalg.norm(np.cross(p2-p1, p1-p3))/np.linalg.norm(p2-p1)\n",
    "            \n",
    "            # TODO: any road segment more than 200 meters away from the GPS point.\n",
    "            if d < 0.05:\n",
    "                edge[1]['ShortestDistance'] = d\n",
    "                candidate_road.append(edge)\n",
    "        # TODO: When a break is detected between time step 𝑡 and time step 𝑡 + 1, \n",
    "        # we remove measured points 𝑧𝑡 and 𝑧𝑡+1 from the model, and check to see \n",
    "        # if the break has been healed. The break is considered healed if the \n",
    "        # measured points at 𝑡 − 1 and 𝑡 + 2 lead to a reconnection in the HMM \n",
    "        # after rechecking the points with the bulleted conditions above. If the \n",
    "        # break is still present, we continue to remove the points on either side \n",
    "        # of the break until either the break is healed, or the break is more than \n",
    "        # 180 seconds long. \n",
    "        if len(candidate_road) == 0:\n",
    "            print(\"No matching roads found within max road distance! Aborting particle filter.\")\n",
    "            return None\n",
    "        candidate_roads.append(candidate_road)\n",
    "    return candidate_roads\n",
    "\n",
    "candidate_roads = get_candidate_roads(Map, trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15985eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 1, fit quality of MAX 0.06, MEAN 0.06, MEDIAN 0.06\n",
      "[0.00420306 0.00420471 0.00420471 0.00420492 0.00412072 0.00412175\n",
      " 0.00413335 0.00412865 0.00412865 0.00414945 0.00412865 0.00420093\n",
      " 0.00417178 0.00415832 0.0041538  0.00412066]\n",
      "[0.06249685 0.06249893 0.06249808 0.06249927 0.06250009 0.06250073\n",
      " 0.06250073 0.06250059 0.06250048 0.06250084 0.06249998 0.06250098\n",
      " 0.06250128 0.06250132 0.06250127 0.06249858]\n",
      "[0.00026268 0.00026279 0.00026279 0.0002628  0.00025755 0.00025761\n",
      " 0.00025834 0.00025804 0.00025804 0.00025934 0.00025804 0.00026256\n",
      " 0.00026074 0.0002599  0.00025962 0.00025754]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Aborted'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model = HMMModel()\n",
    "\n",
    "def train(data, candidate_roads):\n",
    "    data = data.copy()\n",
    "    num_iter = 0\n",
    "    converged = False\n",
    "    for obs in data:\n",
    "        num_iter += 1\n",
    "        fit_quality = model.update_dist(obs, candidate_roads[num_iter-1], num_iter, len(data))\n",
    "        if fit_quality == \"Aborted\":\n",
    "            return \"Aborted\"\n",
    "        print(\"On iteration %d, fit quality of MAX %3.2f, MEAN %3.2f, MEDIAN %3.2f\" % \n",
    "              (num_iter, fit_quality[0], fit_quality[1], fit_quality[2]))\n",
    "    print(\"Done.\")\n",
    "\n",
    "train(trip, candidate_roads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2d54f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "backtracked_trace = model.viterbi()\n",
    "print(backtracked_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fadf3171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37.78703, -122.41139], [37.78739, -122.40823], [37.79258, -122.40776], [37.79475, -122.40801], [37.7994, -122.40903]]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"37.7865352 -122.4118848 0.013359599999994032 0.004619599999998059\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,-244.81914999999998)\"><polyline fill=\"none\" stroke=\"#66cc99\" stroke-width=\"0.00026719199999988066\" points=\"37.78703,-122.41139 37.78739,-122.40823 37.79258,-122.40776 37.79475,-122.40801 37.7994,-122.40903\" opacity=\"0.8\" /></g></svg>",
      "text/plain": [
       "<LINESTRING (37.787 -122.411, 37.787 -122.408, 37.793 -122.408, 37.795 -122....>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(trip[1].latitdue)\n",
    "trip_list = []\n",
    "for point in trip:\n",
    "    trip_list.append([point[1].latitude, point[1].longitude])\n",
    "print(trip_list)\n",
    "LineString(trip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b26c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" />",
      "text/plain": [
       "<LINESTRING EMPTY>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_list = []\n",
    "for point in backtracked_trace:\n",
    "    trip_list.append([point[0], point[1]])\n",
    "print(trip_list)\n",
    "LineString(trip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cae5383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for map visualization\n",
    "\n",
    "import networkx as nx\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69b2867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the standard road network\n",
    "network_fg = folium.FeatureGroup(name='Road Network')\n",
    "\n",
    "for index, row in df_node_SF.iterrows():\n",
    "\n",
    "    # Get the coordinates of the start and end nodes at current index\n",
    "    start_coord = [row['StartNodeLat'], row['StartNodeLong']]\n",
    "    end_coord = [row['EndNodeLat'], row['EndNodeLong']]\n",
    "\n",
    "    # Draw nodes\n",
    "    node_start = folium.Marker([start_coord[0], \n",
    "                   start_coord[1]],\n",
    "                  popup=(df_node_SF['StartNodeID'][index]),\n",
    "                 icon = folium.Icon(color='green',icon='plus'))\n",
    "\n",
    "    node_end = folium.Marker([end_coord[0], \n",
    "                   end_coord[1]],\n",
    "                  popup=(df_node_SF['EndNodeID'][index]),\n",
    "                 icon = folium.Icon(color='blue',icon='plus'))\n",
    "\n",
    "    # Draw road segments between nodes\n",
    "    edges = folium.PolyLine(locations=[start_coord, end_coord], weight=3, color='Red')\n",
    "    \n",
    "    # Add the polyline to the feature group\n",
    "    network_fg.add_child(edges)\n",
    "    network_fg.add_child(node_start)\n",
    "    network_fg.add_child(node_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d2db0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the matched roads\n",
    "matched_fg = folium.FeatureGroup(name='Matched Roads')\n",
    "\n",
    "for i in range(len(trip_list)):\n",
    "\n",
    "    # Draw traces\n",
    "    if i < len(trip_list)-1:\n",
    "        traces = folium.PolyLine(locations=[trip_list[i], trip_list[i+1]], weight=3, color='Green')\n",
    "    \n",
    "    # Add the polyline to the feature group\n",
    "    matched_fg.add_child(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc756f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.map.FeatureGroup at 0x1e9d6ada090>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate distance from node_z to line between node_x and node_y\n",
    "\n",
    "# create example nodes \n",
    "distance_fg = folium.FeatureGroup(name='distance')\n",
    "\n",
    "node_x_coord = [37.7900, -122.5500]\n",
    "node_y_coord = [37.7950, -122.5300]\n",
    "node_z_coord = [37.7990, -122.5450]\n",
    "\n",
    "node_x = folium.Marker([node_x_coord[0], node_x_coord[1]],\n",
    "                  popup=('Latitude: 37.7900 Longitude: -122.5500'),\n",
    "                 icon = folium.Icon(color='green',icon=''))\n",
    "node_y = folium.Marker([node_y_coord[0], node_y_coord[1]],\n",
    "                  popup=('Latitude: 37.7900 Longitude: -122.5300'),\n",
    "                 icon = folium.Icon(color='red',icon=''))\n",
    "node_z = folium.Marker([node_z_coord[0], node_z_coord[1]],\n",
    "                  popup=('Latitude: 37.7950 Longitude: -122.5450'),\n",
    "                 icon = folium.Icon(color='blue',icon=''))\n",
    "line = folium.PolyLine(locations=[node_x_coord, node_y_coord], weight=3, color='Black')\n",
    "\n",
    "distance_fg.add_child(node_x)\n",
    "distance_fg.add_child(node_y)\n",
    "distance_fg.add_child(node_z)\n",
    "distance_fg.add_child(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4333d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37.79170588235295, -122.54317647058821)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def get_perpendicular_point(point, line):\n",
    "    # point: (x, y)\n",
    "    # line: ((x1, y1), (x2, y2))\n",
    "    \n",
    "    x, y = point\n",
    "    x1, y1 = line[0]\n",
    "    x2, y2 = line[1]\n",
    "    \n",
    "    # calculate the slope of the line\n",
    "    if x2 - x1 == 0:\n",
    "        # vertical line\n",
    "        x_intersect = x1\n",
    "        y_intersect = y\n",
    "    else:\n",
    "        slope = (y2 - y1) / (x2 - x1)\n",
    "        intercept = y1 - slope * x1\n",
    "    \n",
    "        # calculate the intersection point of the line and the perpendicular line\n",
    "        x_intersect = (slope*y + x - slope*intercept) / (slope**2 + 1)\n",
    "        y_intersect = (slope*x_intersect) + intercept\n",
    "        \n",
    "    return x_intersect, y_intersect\n",
    "\n",
    "line = [node_x_coord, node_y_coord]\n",
    "closest_road_coord = get_perpendicular_point(node_z_coord, line)\n",
    "print(closest_road_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dead100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.map.FeatureGroup at 0x1e9d6ada090>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate node_v coordinates\n",
    "\n",
    "node_v = folium.Marker([closest_road_coord[0], closest_road_coord[1]],\n",
    "                  popup=('V'),\n",
    "                 icon = folium.Icon(color='black',icon=''))\n",
    "distance_fg.add_child(node_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3fcea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "15\n",
      "range(0, 16)\n",
      "EdgeID              8833.000000\n",
      "StartNodeID         8663.000000\n",
      "EndNodeID           8664.000000\n",
      "L2Distance             0.014952\n",
      "StartNodeLong       -122.402611\n",
      "StartNodeLat          37.749901\n",
      "EndNodeLong         -122.400658\n",
      "EndNodeLat            37.735077\n",
      "ShortestDistance       0.038153\n",
      "Name: 8841, dtype: float64\n",
      "-122.459587\n"
     ]
    }
   ],
   "source": [
    "#print(trip[1][1])\n",
    "#print((len(trip[1][1])))\n",
    "print((len(candidate_roads[0])))\n",
    "print((len(candidate_roads[1])))\n",
    "print(range(len(candidate_roads[0])))\n",
    "print(candidate_roads[0][15][1])\n",
    "print(candidate_roads[0][0][1][4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff78b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n",
      "[37.794075, -122.459587]\n",
      "[37.793568, -122.46389]\n",
      "[0, 1]\n",
      "[37.794964, -122.452103]\n",
      "[37.795692, -122.445938]\n",
      "[0, 2]\n",
      "[37.794964, -122.452103]\n",
      "[37.794075, -122.459587]\n",
      "[0, 3]\n",
      "[37.795692, -122.445938]\n",
      "[37.796028, -122.443108]\n",
      "[0, 4]\n",
      "[37.791428, -122.3853]\n",
      "[37.790779, -122.386093]\n",
      "[0, 5]\n",
      "[37.790779, -122.386093]\n",
      "[37.778801, -122.395721]\n",
      "[0, 6]\n",
      "[37.771461, -122.399391]\n",
      "[37.778801, -122.395721]\n",
      "[0, 7]\n",
      "[37.76292, -122.400047]\n",
      "[37.771461, -122.399391]\n",
      "[0, 8]\n",
      "[37.76292, -122.400047]\n",
      "[37.765938, -122.411339]\n",
      "[0, 9]\n",
      "[37.771145, -122.412689]\n",
      "[37.765938, -122.411339]\n",
      "[0, 10]\n",
      "[37.76292, -122.400047]\n",
      "[37.749901, -122.402611]\n",
      "[0, 11]\n",
      "[37.796028, -122.443108]\n",
      "[37.795185, -122.422157]\n",
      "[0, 12]\n",
      "[37.795185, -122.422157]\n",
      "[37.79184, -122.412582]\n",
      "[0, 13]\n",
      "[37.79184, -122.412582]\n",
      "[37.781567, -122.411339]\n",
      "[0, 14]\n",
      "[37.781567, -122.411339]\n",
      "[37.771145, -122.412689]\n",
      "[0, 15]\n",
      "[37.749901, -122.402611]\n",
      "[37.735077, -122.400658]\n",
      "[1, 0]\n",
      "[37.794964, -122.452103]\n",
      "[37.795692, -122.445938]\n",
      "[1, 1]\n",
      "[37.794964, -122.452103]\n",
      "[37.794075, -122.459587]\n",
      "[1, 2]\n",
      "[37.795692, -122.445938]\n",
      "[37.796028, -122.443108]\n",
      "[1, 3]\n",
      "[37.791428, -122.3853]\n",
      "[37.790779, -122.386093]\n",
      "[1, 4]\n",
      "[37.790779, -122.386093]\n",
      "[37.778801, -122.395721]\n",
      "[1, 5]\n",
      "[37.771461, -122.399391]\n",
      "[37.778801, -122.395721]\n",
      "[1, 6]\n",
      "[37.76292, -122.400047]\n",
      "[37.771461, -122.399391]\n",
      "[1, 7]\n",
      "[37.76292, -122.400047]\n",
      "[37.765938, -122.411339]\n",
      "[1, 8]\n",
      "[37.771145, -122.412689]\n",
      "[37.765938, -122.411339]\n",
      "[1, 9]\n",
      "[37.76292, -122.400047]\n",
      "[37.749901, -122.402611]\n",
      "[1, 10]\n",
      "[37.796028, -122.443108]\n",
      "[37.795185, -122.422157]\n",
      "[1, 11]\n",
      "[37.795185, -122.422157]\n",
      "[37.79184, -122.412582]\n",
      "[1, 12]\n",
      "[37.79184, -122.412582]\n",
      "[37.781567, -122.411339]\n",
      "[1, 13]\n",
      "[37.781567, -122.411339]\n",
      "[37.771145, -122.412689]\n",
      "[1, 14]\n",
      "[37.749901, -122.402611]\n",
      "[37.735077, -122.400658]\n",
      "[2, 0]\n",
      "[37.794964, -122.452103]\n",
      "[37.795692, -122.445938]\n",
      "[2, 1]\n",
      "[37.794964, -122.452103]\n",
      "[37.794075, -122.459587]\n",
      "[2, 2]\n",
      "[37.795692, -122.445938]\n",
      "[37.796028, -122.443108]\n",
      "[2, 3]\n",
      "[37.791428, -122.3853]\n",
      "[37.790779, -122.386093]\n",
      "[2, 4]\n",
      "[37.790779, -122.386093]\n",
      "[37.778801, -122.395721]\n",
      "[2, 5]\n",
      "[37.771461, -122.399391]\n",
      "[37.778801, -122.395721]\n",
      "[2, 6]\n",
      "[37.76292, -122.400047]\n",
      "[37.771461, -122.399391]\n",
      "[2, 7]\n",
      "[37.76292, -122.400047]\n",
      "[37.765938, -122.411339]\n",
      "[2, 8]\n",
      "[37.771145, -122.412689]\n",
      "[37.765938, -122.411339]\n",
      "[2, 9]\n",
      "[37.76292, -122.400047]\n",
      "[37.749901, -122.402611]\n",
      "[2, 10]\n",
      "[37.796028, -122.443108]\n",
      "[37.795185, -122.422157]\n",
      "[2, 11]\n",
      "[37.795185, -122.422157]\n",
      "[37.79184, -122.412582]\n",
      "[2, 12]\n",
      "[37.79184, -122.412582]\n",
      "[37.781567, -122.411339]\n",
      "[2, 13]\n",
      "[37.781567, -122.411339]\n",
      "[37.771145, -122.412689]\n",
      "[2, 14]\n",
      "[37.749901, -122.402611]\n",
      "[37.735077, -122.400658]\n",
      "[3, 0]\n",
      "[37.794964, -122.452103]\n",
      "[37.795692, -122.445938]\n",
      "[3, 1]\n",
      "[37.794964, -122.452103]\n",
      "[37.794075, -122.459587]\n",
      "[3, 2]\n",
      "[37.795692, -122.445938]\n",
      "[37.796028, -122.443108]\n",
      "[3, 3]\n",
      "[37.791428, -122.3853]\n",
      "[37.790779, -122.386093]\n",
      "[3, 4]\n",
      "[37.790779, -122.386093]\n",
      "[37.778801, -122.395721]\n",
      "[3, 5]\n",
      "[37.771461, -122.399391]\n",
      "[37.778801, -122.395721]\n",
      "[3, 6]\n",
      "[37.76292, -122.400047]\n",
      "[37.771461, -122.399391]\n",
      "[3, 7]\n",
      "[37.76292, -122.400047]\n",
      "[37.765938, -122.411339]\n",
      "[3, 8]\n",
      "[37.771145, -122.412689]\n",
      "[37.765938, -122.411339]\n",
      "[3, 9]\n",
      "[37.76292, -122.400047]\n",
      "[37.749901, -122.402611]\n",
      "[3, 10]\n",
      "[37.796028, -122.443108]\n",
      "[37.795185, -122.422157]\n",
      "[3, 11]\n",
      "[37.795185, -122.422157]\n",
      "[37.79184, -122.412582]\n",
      "[3, 12]\n",
      "[37.79184, -122.412582]\n",
      "[37.781567, -122.411339]\n",
      "[3, 13]\n",
      "[37.781567, -122.411339]\n",
      "[37.771145, -122.412689]\n",
      "[3, 14]\n",
      "[37.749901, -122.402611]\n",
      "[37.735077, -122.400658]\n",
      "[4, 0]\n",
      "[37.794964, -122.452103]\n",
      "[37.795692, -122.445938]\n",
      "[4, 1]\n",
      "[37.794964, -122.452103]\n",
      "[37.794075, -122.459587]\n",
      "[4, 2]\n",
      "[37.795692, -122.445938]\n",
      "[37.796028, -122.443108]\n",
      "[4, 3]\n",
      "[37.791428, -122.3853]\n",
      "[37.790779, -122.386093]\n",
      "[4, 4]\n",
      "[37.790779, -122.386093]\n",
      "[37.778801, -122.395721]\n",
      "[4, 5]\n",
      "[37.771461, -122.399391]\n",
      "[37.778801, -122.395721]\n",
      "[4, 6]\n",
      "[37.76292, -122.400047]\n",
      "[37.771461, -122.399391]\n",
      "[4, 7]\n",
      "[37.76292, -122.400047]\n",
      "[37.765938, -122.411339]\n",
      "[4, 8]\n",
      "[37.771145, -122.412689]\n",
      "[37.765938, -122.411339]\n",
      "[4, 9]\n",
      "[37.76292, -122.400047]\n",
      "[37.749901, -122.402611]\n",
      "[4, 10]\n",
      "[37.796028, -122.443108]\n",
      "[37.795185, -122.422157]\n",
      "[4, 11]\n",
      "[37.795185, -122.422157]\n",
      "[37.79184, -122.412582]\n",
      "[4, 12]\n",
      "[37.79184, -122.412582]\n",
      "[37.781567, -122.411339]\n",
      "[4, 13]\n",
      "[37.781567, -122.411339]\n",
      "[37.771145, -122.412689]\n",
      "[4, 14]\n",
      "[37.749901, -122.402611]\n",
      "[37.735077, -122.400658]\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "# DEBUG >> ##################\n",
    "\n",
    "# Trip picked for HMM Training\n",
    "trip_fg = folium.FeatureGroup(name='One Trip for HMM Training')\n",
    "\n",
    "for i in range(len(trip)):\n",
    "\n",
    "    # Draw traces\n",
    "    current_coord = [trip[i][1][0], trip[i][1][1]]\n",
    "    previous_coord = [trip[i][1][4], trip[i][1][5]]\n",
    "    traces = folium.PolyLine(locations=[previous_coord, current_coord], weight=3, color='Blue')\n",
    "    \n",
    "    # Draw nodes\n",
    "    node_end = folium.Marker(current_coord,\n",
    "                  popup=('End'),\n",
    "                 icon = folium.Icon(color='red',icon=''))\n",
    "\n",
    "    node_prev = folium.Marker(previous_coord,\n",
    "                  popup=('Previous'),\n",
    "                 icon = folium.Icon(color='blue',icon=''))\n",
    "\n",
    "    # Add to the feature group\n",
    "    trip_fg.add_child(traces)\n",
    "    trip_fg.add_child(node_end)\n",
    "    trip_fg.add_child(node_prev)\n",
    "\n",
    "# Candidate Roads\n",
    "candidate_fg = folium.FeatureGroup(name='Candidate Roads')\n",
    "\n",
    "#DEBUG\n",
    "cand_size = 0\n",
    "\n",
    "for i in range(len(candidate_roads)):\n",
    "    for j in range(len(candidate_roads[i])):\n",
    "\n",
    "        # Draw traces\n",
    "        start_coord = [candidate_roads[i][j][1][5], candidate_roads[i][j][1][4]]\n",
    "        end_coord = [candidate_roads[i][j][1][7], candidate_roads[i][j][1][6]]\n",
    "        traces = folium.PolyLine(locations=[start_coord, end_coord], weight=3, color='Yellow')\n",
    "        \n",
    "        # Draw nodes\n",
    "        node_end = folium.Marker(end_coord,\n",
    "                    popup=('End'),\n",
    "                    icon = folium.Icon(color='red',icon=''))\n",
    "\n",
    "        node_prev = folium.Marker(start_coord,\n",
    "                    popup=('Previous'),\n",
    "                    icon = folium.Icon(color='blue',icon=''))\n",
    "\n",
    "        # Add to the feature group\n",
    "        candidate_fg.add_child(candidate_fg)\n",
    "        candidate_fg.add_child(node_end)\n",
    "        candidate_fg.add_child(node_prev)\n",
    "\n",
    "        #DEBUG\n",
    "        print([i, j])\n",
    "        cand_size = cand_size + 1\n",
    "        print(start_coord)\n",
    "        print(end_coord)\n",
    "\n",
    "print(cand_size)\n",
    "\n",
    "# << DEBUG ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efc59ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a map centered at San Francisco\n",
    "sf_map = folium.Map(location=[37.759457, -122.444781], zoom_start=12, prefer_canvas=True, control_scale=True)\n",
    "\n",
    "# Add the feature groups to the map\n",
    "#sf_map.add_child(network_fg)\n",
    "#sf_map.add_child(matched_fg)\n",
    "#sf_map.add_child(distance_fg)\n",
    "#sf_map.add_child(trip_fg)\n",
    "sf_map.add_child(candidate_fg)\n",
    "\n",
    "# Add a layer control feature\n",
    "folium.LayerControl().add_to(sf_map)\n",
    "\n",
    "# Add click for coords feature\n",
    "sf_map.add_child(folium.LatLngPopup())\n",
    "\n",
    "# save map\n",
    "#sf_map.save('SF_MAP.html')\n",
    "\n",
    "# display map\n",
    "sf_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5ebdbda498cd1a67a929ee086fffb920f0316c44f60ee7c7e54e99f041477f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
